{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f8ea0e5-ede3-4800-96d7-792dd11efd40",
   "metadata": {},
   "source": [
    "# 1. Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f3b53e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-18 21:36:08.537463: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from torch import nn\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from kobert import get_pytorch_kobert_model\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from transformers.activations import gelu, gelu_new\n",
    "\n",
    "from transformers.modeling_utils import PreTrainedModel, prune_linear_layer, find_pruneable_heads_and_indices\n",
    "from transformers.file_utils import add_start_docstrings_to_model_forward, add_code_sample_docstrings\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import roc_curve\n",
    "from yellowbrick.regressor import RegressionScoreVisualizer\n",
    "from yellowbrick.classifier import ROCAUC\n",
    "from yellowbrick.classifier import ClassificationReport\n",
    "from sklearn import datasets, metrics\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "\n",
    "# new_Added\n",
    "from transformers.models.bert.modeling_bert import BertSelfOutput, BertIntermediate, BertOutput, BertPooler, BertSelfAttention, BertAttention, BertPreTrainedModel, BertEncoder, BertLayer\n",
    "import warnings\n",
    "warnings.filterwarnings('always')  # \"error\", \"ignore\", \"always\", \"default\", \"module\" or \"once\"\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning) # FutureWarning 제거\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22c1b2ee-72b7-49a9-9db3-bd03cbe6a38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def swish(x):\n",
    "    return x * tf.sigmoid(x)\n",
    "\n",
    "def mish(x):\n",
    "    return x * torch.tanh(nn.functional.softplus(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06c60543-da8c-4eb0-af19-c73d941c9578",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACT2FN = {\"gelu\": gelu, \"relu\": torch.nn.functional.relu, \"swish\": swish, \"gelu_new\": gelu_new, \"mish\": mish}\n",
    "\n",
    "BertLayerNorm = torch.nn.LayerNorm\n",
    "BERT_INPUTS_DOCSTRING = r\"\"\"\n",
    "    Args:\n",
    "        input_ids (:obj:`Numpy array` or :obj:`tf.Tensor` of shape :obj:`{0}`):\n",
    "            Indices of input sequence tokens in the vocabulary.\n",
    "\n",
    "            Indices can be obtained using :class:`transformers.BertTokenizer`.\n",
    "            See :func:`transformers.PreTrainedTokenizer.encode` and\n",
    "            :func:`transformers.PreTrainedTokenizer.__call__` for details.\n",
    "\n",
    "            `What are input IDs? <../glossary.html#input-ids>`__\n",
    "        attention_mask (:obj:`Numpy array` or :obj:`tf.Tensor` of shape :obj:`{0}`, `optional`, defaults to :obj:`None`):\n",
    "            Mask to avoid performing attention on padding token indices.\n",
    "            Mask values selected in ``[0, 1]``:\n",
    "            ``1`` for tokens that are NOT MASKED, ``0`` for MASKED tokens.\n",
    "\n",
    "            `What are attention masks? <../glossary.html#attention-mask>`__\n",
    "        token_type_ids (:obj:`Numpy array` or :obj:`tf.Tensor` of shape :obj:`{0}`, `optional`, defaults to :obj:`None`):\n",
    "            Segment token indices to indicate first and second portions of the inputs.\n",
    "            Indices are selected in ``[0, 1]``: ``0`` corresponds to a `sentence A` token, ``1``\n",
    "            corresponds to a `sentence B` token\n",
    "\n",
    "            `What are token type IDs? <../glossary.html#token-type-ids>`__\n",
    "        position_ids (:obj:`Numpy array` or :obj:`tf.Tensor` of shape :obj:`{0}`, `optional`, defaults to :obj:`None`):\n",
    "            Indices of positions of each input sequence tokens in the position embeddings.\n",
    "            Selected in the range ``[0, config.max_position_embeddings - 1]``.\n",
    "\n",
    "            `What are position IDs? <../glossary.html#position-ids>`__\n",
    "        head_mask (:obj:`Numpy array` or :obj:`tf.Tensor` of shape :obj:`(num_heads,)` or :obj:`(num_layers, num_heads)`, `optional`, defaults to :obj:`None`):\n",
    "            Mask to nullify selected heads of the self-attention modules.\n",
    "            Mask values selected in ``[0, 1]``:\n",
    "            :obj:`1` indicates the head is **not masked**, :obj:`0` indicates the head is **masked**.\n",
    "        inputs_embeds (:obj:`Numpy array` or :obj:`tf.Tensor` of shape :obj:`(batch_size, sequence_length, embedding_dim)`, `optional`, defaults to :obj:`None`):\n",
    "            Optionally, instead of passing :obj:`input_ids` you can choose to directly pass an embedded representation.\n",
    "            This is useful if you want more control over how to convert `input_ids` indices into associated vectors\n",
    "            than the model's internal embedding lookup matrix.\n",
    "        training (:obj:`boolean`, `optional`, defaults to :obj:`False`):\n",
    "            Whether to activate dropout modules (if set to :obj:`True`) during training or to de-activate them\n",
    "            (if set to :obj:`False`) for evaluation.\n",
    "        output_attentions (:obj:`bool`, `optional`, defaults to :obj:`None`):\n",
    "            If set to ``True``, the attentions tensors of all attention layers are returned. See ``attentions`` under returned tensors for more detail.\n",
    "\"\"\"\n",
    "\n",
    "_TOKENIZER_FOR_DOC = \"BertTokenizer\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8baa3b2f-cda2-43f2-8dcc-8f4e7dc037ca",
   "metadata": {},
   "source": [
    "# 2. Device Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9ed3a1f-1a38-455f-b507-a97da2f7654f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Current cuda device: 0\n",
      "Count of using GPUs: 1\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print('Device:', device)\n",
    "print('Current cuda device:', torch.cuda.current_device())\n",
    "print('Count of using GPUs:', torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c735ac7a-671e-4c2d-87a9-4f6f3ba5cbb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are some GPU which can be used\n",
      "tensor([0.2246, 0.0868, 0.8848, 0.8563, 0.0572, 0.7038, 0.1495, 0.5259, 0.2179,\n",
      "        0.4351], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "    print(\"There are some GPU which can be used\")\n",
    "    \n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    print(\"There is no GPU which can be used\")\n",
    "        \n",
    "print(torch.rand(10).to(device))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badc3c81-d407-4c4d-a352-844cf5709aa4",
   "metadata": {},
   "source": [
    "# 3. Model & Function Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb20c96a-2d87-41af-9e92-188554fe0bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertEmbeddings_revised(nn.Module):\n",
    "    \"\"\"Construct the embeddings from word, position and token_type embeddings.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.word_embeddings = nn.Embedding(config.vocab_size, config.hidden_size, padding_idx=config.pad_token_id)\n",
    "        self.position_embeddings = nn.Embedding(config.max_position_embeddings, config.hidden_size)\n",
    "        self.token_type_embeddings = nn.Embedding(config.type_vocab_size, config.hidden_size)\n",
    "        self.turn_embeddings = nn.Embedding(config.max_position_embeddings, config.hidden_size)\n",
    "\n",
    "        # self.LayerNorm is not snake-cased to stick with TensorFlow model variable name and be able to load\n",
    "        # any TensorFlow checkpoint file\n",
    "        self.LayerNorm = BertLayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "\n",
    "    def forward(self, input_ids=None, token_type_ids=None, position_ids=None, turn_ids=None, inputs_embeds=None):\n",
    "        if input_ids is not None:\n",
    "            input_shape = input_ids.size()\n",
    "        else:\n",
    "            input_shape = inputs_embeds.size()[:-1]\n",
    "\n",
    "        seq_length = input_shape[1]\n",
    "        device = input_ids.device if input_ids is not None else inputs_embeds.device\n",
    "        if position_ids is None:\n",
    "            position_ids = torch.arange(seq_length, dtype=torch.long, device=device)\n",
    "            position_ids = position_ids.unsqueeze(0).expand(input_shape)\n",
    "            \n",
    "        if token_type_ids is None:\n",
    "            token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=device)\n",
    "\n",
    "        if inputs_embeds is None:\n",
    "            inputs_embeds = self.word_embeddings(input_ids)\n",
    "            \n",
    "        if turn_ids is None:\n",
    "            turn_ids = torch.zeros(input_shape, dtype=torch.long, device=device)\n",
    "            for i in range(len(input_ids)):\n",
    "                temp = 2\n",
    "                for j in range(len(input_ids[i])):\n",
    "                    if (input_ids[i][j] == 101 or input_ids[i][j] == 102 or input_ids[i][j] == 0):\n",
    "                        if temp == 1:\n",
    "                            temp = 2\n",
    "                        elif temp == 2:\n",
    "                            temp = 1\n",
    "                        turn_ids[i][j] = 0\n",
    "                        continue\n",
    "                    turn_ids[i][j] = temp\n",
    "        #turn_ids = turn_ids.clone().detach().long()\n",
    "        #turn_ids = torch.tensor(turn_ids).to(device).long()\n",
    "        #turn_ids=turn_ids.type(torch.LongTensor)\n",
    "        position_embeddings = self.position_embeddings(position_ids)\n",
    "        token_type_embeddings = self.token_type_embeddings(token_type_ids)\n",
    "        turn_embeddings = self.turn_embeddings(turn_ids)\n",
    "\n",
    "        embeddings = inputs_embeds + position_embeddings + token_type_embeddings + turn_embeddings\n",
    "        embeddings = self.LayerNorm(embeddings)\n",
    "        embeddings = self.dropout(embeddings)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3547c30a-366e-4fa1-97d2-28aa2b5c6a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertModel_revised(BertPreTrainedModel):\n",
    "    \"\"\"\n",
    "\n",
    "    The model can behave as an encoder (with only self-attention) as well\n",
    "    as a decoder, in which case a layer of cross-attention is added between\n",
    "    the self-attention layers, following the architecture described in `Attention is all you need`_ by Ashish Vaswani,\n",
    "    Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser and Illia Polosukhin.\n",
    "\n",
    "    To behave as an decoder the model needs to be initialized with the\n",
    "    :obj:`is_decoder` argument of the configuration set to :obj:`True`; an\n",
    "    :obj:`encoder_hidden_states` is expected as an input to the forward pass.\n",
    "\n",
    "    .. _`Attention is all you need`:\n",
    "        https://arxiv.org/abs/1706.03762\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.config = config\n",
    "\n",
    "        self.embeddings = BertEmbeddings_revised(config)\n",
    "        self.encoder = BertEncoder(config)\n",
    "        self.pooler = BertPooler(config)\n",
    "\n",
    "        self.init_weights()\n",
    "        \n",
    "    def get_input_embeddings(self):\n",
    "        return self.embeddings.word_embeddings\n",
    "\n",
    "    def set_input_embeddings(self, value):\n",
    "        self.embeddings.word_embeddings = value\n",
    "            \n",
    "    def _prune_heads(self, heads_to_prune):\n",
    "        \"\"\" Prunes heads of the model.\n",
    "            heads_to_prune: dict of {layer_num: list of heads to prune in this layer}\n",
    "            See base class PreTrainedModel\n",
    "        \"\"\"\n",
    "        for layer, heads in heads_to_prune.items():\n",
    "            self.encoder.layer[layer].attention.prune_heads(heads)\n",
    "    \n",
    "    @add_start_docstrings_to_model_forward(BERT_INPUTS_DOCSTRING.format(\"(batch_size, sequence_length)\"))\n",
    "    @add_code_sample_docstrings(processor_class=_TOKENIZER_FOR_DOC, checkpoint=\"bert-base-uncased\")\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        turn_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        encoder_hidden_states=None,\n",
    "        encoder_attention_mask=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "    ):\n",
    "        r\"\"\"\n",
    "    Return:\n",
    "        :obj:`tuple(torch.FloatTensor)` comprising various elements depending on the configuration (:class:`~transformers.BertConfig`) and inputs:\n",
    "        last_hidden_state (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, sequence_length, hidden_size)`):\n",
    "            Sequence of hidden-states at the output of the last layer of the model.\n",
    "        pooler_output (:obj:`torch.FloatTensor`: of shape :obj:`(batch_size, hidden_size)`):\n",
    "            Last layer hidden-state of the first token of the sequence (classification token)\n",
    "            further processed by a Linear layer and a Tanh activation function. The Linear\n",
    "            layer weights are trained from the next sentence prediction (classification)\n",
    "            objective during pre-training.\n",
    "\n",
    "            This output is usually *not* a good summary\n",
    "            of the semantic content of the input, you're often better with averaging or pooling\n",
    "            the sequence of hidden-states for the whole input sequence.\n",
    "        hidden_states (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``output_hidden_states=True`` is passed or when ``config.output_hidden_states=True``):\n",
    "            Tuple of :obj:`torch.FloatTensor` (one for the output of the embeddings + one for the output of each layer)\n",
    "            of shape :obj:`(batch_size, sequence_length, hidden_size)`.\n",
    "\n",
    "            Hidden-states of the model at the output of each layer plus the initial embedding outputs.\n",
    "        attentions (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``output_attentions=True`` is passed or when ``config.output_attentions=True``):\n",
    "            Tuple of :obj:`torch.FloatTensor` (one for each layer) of shape\n",
    "            :obj:`(batch_size, num_heads, sequence_length, sequence_length)`.\n",
    "\n",
    "            Attentions weights after the attention softmax, used to compute the weighted average in the self-attention\n",
    "            heads.\n",
    "        \"\"\"\n",
    "        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n",
    "        output_hidden_states = (\n",
    "            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n",
    "        )\n",
    "\n",
    "        if input_ids is not None and inputs_embeds is not None:\n",
    "            raise ValueError(\"You cannot specify both input_ids and inputs_embeds at the same time\")\n",
    "        elif input_ids is not None:\n",
    "            input_shape = input_ids.size()\n",
    "        elif inputs_embeds is not None:\n",
    "            input_shape = inputs_embeds.size()[:-1]\n",
    "        else:\n",
    "            raise ValueError(\"You have to specify either input_ids or inputs_embeds\")\n",
    "\n",
    "        device = input_ids.device if input_ids is not None else inputs_embeds.device\n",
    "\n",
    "        if attention_mask is None:\n",
    "            attention_mask = torch.ones(input_shape, device=device)\n",
    "        if token_type_ids is None:\n",
    "            token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=device)\n",
    "        if turn_ids is None:\n",
    "            turn_ids = torch.zeros(input_shape, dtype=torch.long, device=device)\n",
    "\n",
    "        # We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]\n",
    "        # ourselves in which case we just need to make it broadcastable to all heads.\n",
    "        extended_attention_mask: torch.Tensor = self.get_extended_attention_mask(attention_mask, input_shape, device)\n",
    "\n",
    "        # If a 2D ou 3D attention mask is provided for the cross-attention\n",
    "        # we need to make broadcastabe to [batch_size, num_heads, seq_length, seq_length]\n",
    "        if self.config.is_decoder and encoder_hidden_states is not None:\n",
    "            encoder_batch_size, encoder_sequence_length, _ = encoder_hidden_states.size()\n",
    "            encoder_hidden_shape = (encoder_batch_size, encoder_sequence_length)\n",
    "            if encoder_attention_mask is None:\n",
    "                encoder_attention_mask = torch.ones(encoder_hidden_shape, device=device)\n",
    "            encoder_extended_attention_mask = self.invert_attention_mask(encoder_attention_mask)\n",
    "        else:\n",
    "            encoder_extended_attention_mask = None\n",
    "\n",
    "        # Prepare head mask if needed\n",
    "        # 1.0 in head_mask indicate we keep the head\n",
    "        # attention_probs has shape bsz x n_heads x N x N\n",
    "        # input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\n",
    "        # and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\n",
    "        head_mask = self.get_head_mask(head_mask, self.config.num_hidden_layers)\n",
    "\n",
    "        embedding_output = self.embeddings(\n",
    "            input_ids=input_ids, position_ids=position_ids, token_type_ids=token_type_ids, turn_ids=turn_ids, inputs_embeds=inputs_embeds\n",
    "        )\n",
    "        encoder_outputs = self.encoder(\n",
    "            embedding_output,\n",
    "            attention_mask=extended_attention_mask,\n",
    "            head_mask=head_mask,\n",
    "            encoder_hidden_states=encoder_hidden_states,\n",
    "            encoder_attention_mask=encoder_extended_attention_mask,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "        )\n",
    "        sequence_output = encoder_outputs[0]\n",
    "        pooled_output = self.pooler(sequence_output)\n",
    "\n",
    "        outputs = (sequence_output, pooled_output,) + encoder_outputs[\n",
    "            1:\n",
    "        ]  # add hidden_states and attentions if they are here\n",
    "        return outputs  # sequence_output, pooled_output, (hidden_states), (attentions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b542e910-2ff8-45d6-a1d4-1cfe7ab2a69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertForSequenceClassification_revised(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "\n",
    "        self.bert = BertModel_revised(config)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    @add_start_docstrings_to_model_forward(BERT_INPUTS_DOCSTRING.format(\"(batch_size, sequence_length)\"))\n",
    "    @add_code_sample_docstrings(processor_class=_TOKENIZER_FOR_DOC, checkpoint=\"bert-base-uncased\")\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        turn_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        labels=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "    ):\n",
    "\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            turn_ids=turn_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "        )\n",
    "\n",
    "        pooled_output = outputs[1]\n",
    "\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        outputs = (logits,) + outputs[2:]  # add hidden states and attention if they are here\n",
    "\n",
    "        if labels is not None:\n",
    "            if self.num_labels == 1:\n",
    "                #  We are doing regression\n",
    "                loss_fct = MSELoss()\n",
    "                loss = loss_fct(logits.view(-1), labels.view(-1))\n",
    "            else:\n",
    "                loss_fct = CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            outputs = (loss,) + outputs\n",
    "\n",
    "        return outputs  # loss, logits, (hidden_states), (attentions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f5486fd-2bbe-490b-b70c-208fb64fef21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확도 계산 함수\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = preds.flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "    \n",
    "    \n",
    "# 시간 표시 함수\n",
    "def format_time(elapsed):\n",
    "\n",
    "    # 반올림\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # hh:mm:ss으로 형태 변경\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "\n",
    "\n",
    "def evaluation_metrics(preds, labels):\n",
    "    pred_flat = preds.flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    \n",
    "    accuracy=accuracy_score(pred_flat, labels_flat)\n",
    "    precision=precision_score(pred_flat, labels_flat, average='macro')\n",
    "    recall=recall_score(pred_flat, labels_flat, average='macro')\n",
    "    f1=f1_score(pred_flat, labels_flat, average='macro')\n",
    "    RMSE = mean_squared_error(labels_flat, pred_flat)**0.5\n",
    "    \n",
    "    return accuracy, precision, recall, f1, RMSE\n",
    "\n",
    "def softmax(num):\n",
    "    exp=np.exp(num)\n",
    "    sum_exp=np.sum(exp)\n",
    "    y=exp/sum_exp\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e904b1-59ef-42a0-b2ed-111e8ab2bef3",
   "metadata": {},
   "source": [
    "# 4. Chatbot Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e2fc00-fb51-45a3-8727-9b538c56602d",
   "metadata": {},
   "source": [
    "## 4.1 Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef87704b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot_data=pd.read_csv('ChatbotData.csv', encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53722953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edd06761",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_list=[]\n",
    "\n",
    "for idx,row in chatbot_data.iterrows():\n",
    "    Q=row['Q']\n",
    "    A=row['A']\n",
    "    input=\"[CLS] \"+Q+\" [SEP] \"+A+\" [SEP]\"\n",
    "    input_list.append(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53210ace-ae3b-4ae7-b51c-71accc2c420a",
   "metadata": {},
   "outputs": [],
   "source": [
    "label=chatbot_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7343dc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list=label.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4c1de49-269b-44e2-955a-5289a8bd2f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\", do_lower_case=False)\n",
    "tokenized_input = [tokenizer.tokenize(input) for input in input_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3f15653-7cc0-4d65-af0e-6942c57260fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] 12시 땡! [SEP] 하루가 또 가네요. [SEP]\n",
      "['[CLS]', '12', '##시', '[UNK]', '!', '[SEP]', '하', '##루', '##가', '또', '가', '##네', '##요', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "print(input_list[0])\n",
    "print(tokenized_input[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "651f69fc-ba30-4b2d-9f70-d16a49f186cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 128 \n",
    "\n",
    "input_id = [tokenizer.convert_tokens_to_ids(token) for token in tokenized_input]\n",
    "input_id = pad_sequences(input_id, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "853021f3-85df-4513-a0b0-f2465364cffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_masks = []\n",
    "\n",
    "for num in input_id:\n",
    "    attention_mask = [float(i>0) for i in num]\n",
    "    attention_masks.append(attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebe5f227-8829-4338-a7f1-2802378303b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(input_id, label_list, random_state=2, test_size=0.4, shuffle=True)\n",
    "mask_train, mask_test, temp_train_id, temp_test_id = train_test_split(attention_masks, input_id, random_state=2, test_size=0.4, shuffle=True)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29bd66eb-2f6e-4c97-a520-76bdf6b509ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val, x_eval, y_val, y_eval = train_test_split(x_test, y_test, test_size=0.2, random_state=2, shuffle=True)\n",
    "mask_val, mask_eval, _, _ = train_test_split(mask_test, temp_test_id, random_state=2, test_size=0.2, shuffle=True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c39fd95-ef1c-449d-82da-9e45ed906d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = torch.tensor(x_train)\n",
    "train_labels = torch.tensor(y_train)\n",
    "train_masks = torch.tensor(mask_train)\n",
    "\n",
    "val_inputs = torch.tensor(x_val)\n",
    "val_labels = torch.tensor(y_val)\n",
    "val_masks = torch.tensor(mask_val)  \n",
    "\n",
    "eval_inputs1 = torch.tensor(x_eval)\n",
    "eval_labels1 = torch.tensor(y_eval)\n",
    "eval_masks1 = torch.tensor(mask_eval)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "436c7827-8a90-4066-ab5e-a79f94f89f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
    "\n",
    "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=BATCH_SIZE)\n",
    "\n",
    "eval_data1 = TensorDataset(eval_inputs1, eval_masks1, eval_labels1)\n",
    "eval_sampler1 = SequentialSampler(eval_data1)\n",
    "eval_dataloader1 = DataLoader(eval_data1, sampler=eval_sampler1, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b12bccd-407c-45d8-9c55-5b35345800df",
   "metadata": {},
   "source": [
    "## 4.2 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa3e3331-da83-487b-9386-b78719659aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification_revised: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification_revised from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification_revised from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification_revised were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'bert.embeddings.turn_embeddings.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification_revised(\n",
       "  (bert): BertModel_revised(\n",
       "    (embeddings): BertEmbeddings_revised(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (turn_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SemanticScorePrediction = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=3)\n",
    "SemanticScorePrediction = BertForSequenceClassification_revised.from_pretrained(\"bert-base-multilingual-cased\", num_labels=3)\n",
    "SemanticScorePrediction.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa1b5f0b-012f-4735-94f8-3ee97226ff24",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(SemanticScorePrediction.parameters(),\n",
    "                  lr = 2e-5, # 학습률(learning rate)\n",
    "                  eps = 1e-8 \n",
    "                )\n",
    "\n",
    "# 에폭수\n",
    "epochs = 30\n",
    "\n",
    "# 총 훈련 스텝 : 배치반복 횟수 * 에폭\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# 스케줄러 생성\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "050e2180-87d5-4ca1-b534-998c2cd05369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.68\n",
      "  Training epcoh took: 0:00:34\n",
      "\n",
      "======== Epoch 2 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.44\n",
      "  Training epcoh took: 0:00:32\n",
      "\n",
      "======== Epoch 3 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.34\n",
      "  Training epcoh took: 0:00:33\n",
      "\n",
      "======== Epoch 4 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.26\n",
      "  Training epcoh took: 0:00:33\n",
      "\n",
      "======== Epoch 5 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.20\n",
      "  Training epcoh took: 0:00:33\n",
      "\n",
      "======== Epoch 6 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.16\n",
      "  Training epcoh took: 0:00:33\n",
      "\n",
      "======== Epoch 7 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.14\n",
      "  Training epcoh took: 0:00:33\n",
      "\n",
      "======== Epoch 8 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.11\n",
      "  Training epcoh took: 0:00:33\n",
      "\n",
      "======== Epoch 9 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.09\n",
      "  Training epcoh took: 0:00:33\n",
      "\n",
      "======== Epoch 10 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.07\n",
      "  Training epcoh took: 0:00:33\n",
      "\n",
      "======== Epoch 11 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.06\n",
      "  Training epcoh took: 0:00:34\n",
      "\n",
      "======== Epoch 12 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.06\n",
      "  Training epcoh took: 0:00:32\n",
      "\n",
      "======== Epoch 13 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.04\n",
      "  Training epcoh took: 0:00:33\n",
      "\n",
      "======== Epoch 14 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.05\n",
      "  Training epcoh took: 0:00:33\n",
      "\n",
      "======== Epoch 15 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.04\n",
      "  Training epcoh took: 0:00:33\n",
      "\n",
      "======== Epoch 16 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.04\n",
      "  Training epcoh took: 0:00:33\n",
      "\n",
      "======== Epoch 17 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.03\n",
      "  Training epcoh took: 0:00:33\n",
      "\n",
      "======== Epoch 18 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.03\n",
      "  Training epcoh took: 0:00:32\n",
      "\n",
      "======== Epoch 19 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.03\n",
      "  Training epcoh took: 0:00:33\n",
      "\n",
      "======== Epoch 20 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epcoh took: 0:00:34\n",
      "\n",
      "======== Epoch 21 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epcoh took: 0:00:33\n",
      "\n",
      "======== Epoch 22 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epcoh took: 0:00:33\n",
      "\n",
      "======== Epoch 23 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epcoh took: 0:00:33\n",
      "\n",
      "======== Epoch 24 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:00:34\n",
      "\n",
      "======== Epoch 25 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:00:33\n",
      "\n",
      "======== Epoch 26 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:00:33\n",
      "\n",
      "======== Epoch 27 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:00:33\n",
      "\n",
      "======== Epoch 28 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:00:33\n",
      "\n",
      "======== Epoch 29 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:00:33\n",
      "\n",
      "======== Epoch 30 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:00:33\n"
     ]
    }
   ],
   "source": [
    "#랜덤시드 고정\n",
    "seed_val = 14\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "#그래디언트 초기화\n",
    "SemanticScorePrediction.zero_grad()\n",
    "\n",
    "# 학습\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # 시작 시간 설정\n",
    "    t0 = time.time()\n",
    "\n",
    "    # 로스 초기화\n",
    "    total_loss = 0\n",
    "\n",
    "    # 훈련모드로 변경\n",
    "    SemanticScorePrediction.train()\n",
    "        \n",
    "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # 경과 정보 표시\n",
    "        if step % 500 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # 배치를 GPU에 넣음\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        # 배치에서 데이터 추출\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        for i in range(len(b_labels)):\n",
    "            b_labels[i] += 1\n",
    "\n",
    "        # Forward 수행\n",
    "        outputs = SemanticScorePrediction(b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask,\n",
    "                        turn_ids = None,\n",
    "                        labels=b_labels)\n",
    "        \n",
    "        # 로스 구함\n",
    "        loss = outputs[0]\n",
    "\n",
    "        # 총 로스 계산\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backward 수행으로 그래디언트 계산\n",
    "        loss.backward()\n",
    "\n",
    "        # 그래디언트 클리핑\n",
    "        torch.nn.utils.clip_grad_norm_(SemanticScorePrediction.parameters(), 1.0)\n",
    "\n",
    "        # 그래디언트를 통해 가중치 파라미터 업데이트\n",
    "        optimizer.step()\n",
    "\n",
    "        # 스케줄러로 학습률 감소\n",
    "        scheduler.step()\n",
    "\n",
    "        # 그래디언트 초기화\n",
    "        SemanticScorePrediction.zero_grad()\n",
    "\n",
    "    # 평균 로스 계산\n",
    "    avg_train_loss = total_loss / len(train_dataloader)            \n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268f90bd-d3e2-4a9e-851b-b5bbcf8e3ba0",
   "metadata": {},
   "source": [
    "## 4.3 Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c8d7756f-7064-464d-9fd6-d478e67ecdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relation_score_prediction(logtis):\n",
    "    logits_numpy=logits.detach().cpu().numpy()\n",
    "    indicator_list=[]\n",
    "    score_list=[]\n",
    "    \n",
    "    Input_layer = layers.InputLayer(input_shape=(1,))\n",
    "    hidden_layer1 = layers.Dense(8, activation='swish')\n",
    "    hidden_layer2 = layers.Dense(4, activation='swish')\n",
    "    output_layer = layers.Dense(1, activation='tanh')\n",
    "    \n",
    "    model = tf.keras.Sequential([\n",
    "        Input_layer,\n",
    "        hidden_layer1,\n",
    "        hidden_layer2,\n",
    "        output_layer,\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='Adam', loss='mse')\n",
    "    \n",
    "    for i in range(len(logits)):\n",
    "        j = np.argmax(logits_numpy[i])\n",
    "        k = np.argmin(logits_numpy[i])\n",
    "        ground_truth = np.zeros(3)\n",
    "        ground_truth[j] = 5\n",
    "        ground_truth[k] = -5\n",
    "        model.fit(logits_numpy[i], ground_truth)\n",
    "        \n",
    "        \n",
    "    for i in range(len(logits)):\n",
    "        semantic_indicator=model.predict(logits_numpy[i])\n",
    "        indicator_list.append(semantic_indicator)\n",
    "        \n",
    "    for i in range(len(indicator_list)):\n",
    "        indicator_list[i][0]=(-1)*indicator_list[i][0]\n",
    "        sum=0\n",
    "        for j in range(len(indicator_list[i])):\n",
    "            sum=sum+indicator_list[i][j]\n",
    "        sum=sum/3\n",
    "        score_list.append(sum)\n",
    "            \n",
    "    return score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "56514760-4457-47e4-bbdd-2c50df26f839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Accuracy]: 86.42%\n",
      "  [Precision]: 85.87%\n",
      "  [Recall]: 86.55%\n",
      "  [F1_Score]: 86.17%\n",
      "  [RMSE]: 0.46\n",
      "  Validation took: 0:00:05\n"
     ]
    }
   ],
   "source": [
    "#Validation\n",
    "#시작 시간 설정\n",
    "t0 = time.time()\n",
    "\n",
    "logits_results = np.array([])\n",
    "label_ids_results = np.array([])\n",
    "\n",
    "#데이터로더에서 배치만큼 반복하여 가져옴\n",
    "for batch in val_dataloader:\n",
    "    # 배치를 GPU에 넣음\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "    # 배치에서 데이터 추출\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "    for i in range(len(b_labels)):\n",
    "        b_labels[i] += 1\n",
    "\n",
    "    # 그래디언트 계산 안함\n",
    "    with torch.no_grad():     \n",
    "        # Forward 수행\n",
    "        outputs = SemanticScorePrediction(b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask,\n",
    "                        turn_ids = None,\n",
    "                        labels=b_labels)\n",
    "    #로짓 구함\n",
    "    logits = outputs[1]\n",
    "    \n",
    "    \n",
    "    # CPU로 데이터 이동\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy() \n",
    "    \n",
    "    logits = np.argmax(logits, axis=1)\n",
    "\n",
    "    logits_results = np.append(logits_results, logits)\n",
    "    label_ids_results = np.append(label_ids_results, label_ids)\n",
    "    \n",
    "\n",
    "# 출력 로스과 라벨을 비교하여 정확도 계산\n",
    "tmp_eval_accuracy = flat_accuracy(logits_results, label_ids_results)\n",
    "#eval_accuracy += tmp_eval_accuracy\n",
    "#nb_eval_steps += 1\n",
    "acc, prec, recall, f1, RMSE = evaluation_metrics(logits_results, label_ids_results)\n",
    "\n",
    "print('  [Accuracy]: {:.2f}%'.format(acc * 100))\n",
    "print('  [Precision]: {:.2f}%'.format(prec * 100))\n",
    "print('  [Recall]: {:.2f}%'.format(recall * 100))\n",
    "print('  [F1_Score]: {:.2f}%'.format(f1 * 100))\n",
    "print('  [RMSE]: {:.2f}'.format(RMSE))\n",
    "print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5e2678-d562-4d80-bb0c-9208bc1276f2",
   "metadata": {},
   "source": [
    "## 4.4 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5ebb091c-24e6-486a-8a39-0be8bec27089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Accuracy]: 86.89%\n",
      "  [Precision]: 86.14%\n",
      "  [Recall]: 86.71%\n",
      "  [F1_Score]: 86.40%\n",
      "  [RMSE]: 0.47\n",
      "  Evaluation  took: 0:00:01\n"
     ]
    }
   ],
   "source": [
    "#Evaluation\n",
    "#시작 시간 설정\n",
    "t0 = time.time()\n",
    "\n",
    "# 평가모드로 변경\n",
    "SemanticScorePrediction.eval()\n",
    "\n",
    "score_list_final=[]\n",
    "# 변수 초기화\n",
    "eval_loss, eval_accuracy = 0, 0\n",
    "nb_eval_steps, nb_eval_examples = 0, 0\n",
    "logits_results = np.array([])\n",
    "label_ids_results = np.array([])\n",
    "\n",
    "# 데이터로더에서 배치만큼 반복하여 가져옴\n",
    "for step, batch in enumerate(eval_dataloader1):\n",
    "    # 경과 정보 표시\n",
    "    if step % 100 == 0 and not step == 0:\n",
    "        elapsed = format_time(time.time() - t0)\n",
    "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(eval_dataloader1), elapsed))\n",
    "\n",
    "    # 배치를 GPU에 넣음\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    \n",
    "    # 배치에서 데이터 추출\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    \n",
    "    for i in range(len(b_labels)):\n",
    "            b_labels[i] += 1\n",
    "        \n",
    "    # 그래디언트 계산 안함\n",
    "    with torch.no_grad():     \n",
    "        # Forward 수행\n",
    "        outputs = SemanticScorePrediction(b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        turn_ids=None,\n",
    "                        attention_mask=b_input_mask)\n",
    "    \n",
    "    # 로스 구함\n",
    "    logits = outputs[0]\n",
    "    #score_list=relation_score_prediction(logits)\n",
    "    #score_list_final.apppend(score_list)\n",
    "    \n",
    "    # CPU로 데이터 이동\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    \n",
    "    logits = np.argmax(logits, axis=1)\n",
    "\n",
    "    logits_results = np.append(logits_results, logits)\n",
    "    label_ids_results = np.append(label_ids_results, label_ids)\n",
    "    \n",
    "\n",
    "# 출력 로스과 라벨을 비교하여 정확도 계산\n",
    "tmp_eval_accuracy = flat_accuracy(logits_results, label_ids_results)\n",
    "eval_accuracy += tmp_eval_accuracy\n",
    "nb_eval_steps += 1\n",
    "acc, prec, recall, f1, RMSE = evaluation_metrics(logits_results, label_ids_results)\n",
    "\n",
    "print('  [Accuracy]: {:.2f}%'.format(acc * 100))\n",
    "print('  [Precision]: {:.2f}%'.format(prec * 100))\n",
    "print('  [Recall]: {:.2f}%'.format(recall * 100))\n",
    "print('  [F1_Score]: {:.2f}%'.format(f1 * 100))\n",
    "print('  [RMSE]: {:.2f}'.format(RMSE))\n",
    "print(\"  Evaluation  took: {:}\".format(format_time(time.time() - t0)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d675bf",
   "metadata": {},
   "source": [
    "## 5. Everyone's corpus: Messenger "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48e44f2-4c65-4bf2-88de-a2e6e42005c6",
   "metadata": {},
   "source": [
    "## 5.1 Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fda17c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'NIKL_OM_2021_v1.0/NIKL_OM_2021_v1.0/국립국어원 온라인 대화 말뭉치 2021(버전 1.0)/'\n",
    "file_list = os.listdir(path)\n",
    "file_list_json = [file for file in file_list if file.endswith('.json')] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "83c8e5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n"
     ]
    }
   ],
   "source": [
    "data_dict={}\n",
    "data_arr=[]\n",
    "\n",
    "num=0\n",
    "for file in file_list_json:\n",
    "    input_data=\"[CLS]\"\n",
    "    temp='1'\n",
    "    with open (path+file, \"r\", encoding=\"UTF8\") as f:\n",
    "        contents=f.read()\n",
    "        json_data=json.loads(contents)\n",
    "        relation=json_data[\"document\"][0][\"metadata\"][\"setting\"][\"relation\"]\n",
    "        utter=json_data[\"document\"][0][\"utterance\"]\n",
    "        speaker1_gender=json_data[\"document\"][0][\"metadata\"][\"speaker\"][0][\"sex\"]\n",
    "        speaker2_gender=json_data[\"document\"][0][\"metadata\"][\"speaker\"][1][\"sex\"]\n",
    "        if(speaker1_gender==speaker2_gender):\n",
    "            label=0\n",
    "        else:\n",
    "            label=\"none\"\n",
    "        \n",
    "        for utter_num in range(len(utter)):\n",
    "            if temp==utter[utter_num]['speaker_id']:\n",
    "                input_data=input_data+\" \"+utter[utter_num][\"form\"]\n",
    "                temp=utter[utter_num]['speaker_id']\n",
    "            else:\n",
    "                input_data=input_data+\" [SEP] \"+utter[utter_num][\"form\"]\n",
    "                temp=utter[utter_num]['speaker_id']\n",
    "                \n",
    "        input_data=input_data+\" [SEP] \"\n",
    "        \n",
    "        num=num+1\n",
    "        if(num%10000==0):\n",
    "            print(num)\n",
    "            \n",
    "        data_dict={\n",
    "            'data':input_data,\n",
    "            'label':label,\n",
    "            'relation':relation,\n",
    "            'speaker1_gender':speaker1_gender,\n",
    "            'speaker2_gender':speaker2_gender\n",
    "        }\n",
    "        data_arr.append(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d2a950d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('malmungchi_chatbot.csv','w',encoding='utf-8-sig') as csv_file:\n",
    "    fieldnames = ['data', 'label','relation','speaker1_gender','speaker2_gender']\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for data in data_arr:\n",
    "        writer.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ce5b723-a566-4231-bea0-236e434e7291",
   "metadata": {},
   "outputs": [],
   "source": [
    "malmungchi_chatbot_data=pd.read_csv('malmungchi_chatbot.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "68301608-08f4-49f3-929d-23619d0d9483",
   "metadata": {},
   "outputs": [],
   "source": [
    "malmungchi_4000_samples=pd.read_csv('malmugchi_chabot_4000_samples.csv', encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dfcbea14-797e-45ee-9bcb-4f71510f1672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>label</th>\n",
       "      <th>relation</th>\n",
       "      <th>speaker1_gender</th>\n",
       "      <th>speaker2_gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CLS] 전 이제 집 도착해서 저녁먹었는데 저녁 드셨나요?ㅎㅎ [SEP] 네 게 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>낯선 사람</td>\n",
       "      <td>여성</td>\n",
       "      <td>여성</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[CLS] 안녕 [SEP] 나 옷 삼 [SEP] 뭔 옷 [SEP] 에이블리에서 후드...</td>\n",
       "      <td>0</td>\n",
       "      <td>가족&gt;형제자매</td>\n",
       "      <td>여성</td>\n",
       "      <td>여성</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[CLS] [SEP] 저는 홍차! [SEP] 아아vs뜨아? [SEP] 아아요! 차가...</td>\n",
       "      <td>0</td>\n",
       "      <td>낯선 사람</td>\n",
       "      <td>여성</td>\n",
       "      <td>남성</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[CLS] name2 안녕 [SEP] 안녕 name1 [SEP] 날씨 좋다\\n일하니...</td>\n",
       "      <td>1</td>\n",
       "      <td>낯선 사람</td>\n",
       "      <td>여성</td>\n",
       "      <td>남성</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[CLS] [SEP] 요즘 날씨가 많이 선선해졌죠?!?! 아침엔 꽤나 쌀쌀하네요 오...</td>\n",
       "      <td>0</td>\n",
       "      <td>낯선 사람</td>\n",
       "      <td>여성</td>\n",
       "      <td>여성</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data  label relation  \\\n",
       "0  [CLS] 전 이제 집 도착해서 저녁먹었는데 저녁 드셨나요?ㅎㅎ [SEP] 네 게 ...      0    낯선 사람   \n",
       "1  [CLS] 안녕 [SEP] 나 옷 삼 [SEP] 뭔 옷 [SEP] 에이블리에서 후드...      0  가족>형제자매   \n",
       "2  [CLS] [SEP] 저는 홍차! [SEP] 아아vs뜨아? [SEP] 아아요! 차가...      0    낯선 사람   \n",
       "3  [CLS] name2 안녕 [SEP] 안녕 name1 [SEP] 날씨 좋다\\n일하니...      1    낯선 사람   \n",
       "4  [CLS] [SEP] 요즘 날씨가 많이 선선해졌죠?!?! 아침엔 꽤나 쌀쌀하네요 오...      0    낯선 사람   \n",
       "\n",
       "  speaker1_gender speaker2_gender  \n",
       "0              여성              여성  \n",
       "1              여성              여성  \n",
       "2              여성              남성  \n",
       "3              여성              남성  \n",
       "4              여성              여성  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "malmungchi_4000_samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d34efdf5-149c-44d1-97ef-929768902673",
   "metadata": {},
   "outputs": [],
   "source": [
    "malmungchi_4000_samples_label=malmungchi_4000_samples['label']\n",
    "malmungchi_label_list=malmungchi_4000_samples_label.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "de6be1fc-fa7d-4ea0-be28-b6c9f5d97921",
   "metadata": {},
   "outputs": [],
   "source": [
    "malmungchi_4000_samples_data=malmungchi_4000_samples['data']\n",
    "malmungchi_data_list=malmungchi_4000_samples_data.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dc22fe9e-7114-459b-9951-ecdbbebe420a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in malmungchi_data_list:\n",
    "    data=str(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cd186373-06bc-48ad-87ec-2c958839eba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\", do_lower_case=False)\n",
    "tokenized_malmungchi_input = [tokenizer.tokenize(str(input)) for input in malmungchi_data_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "71da9190-2d92-4c55-92c7-1307e87a37d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 500\n",
    "\n",
    "malmungchi_input_id = [tokenizer.convert_tokens_to_ids(token) for token in tokenized_malmungchi_input]\n",
    "malmungchi_input_id = pad_sequences(malmungchi_input_id, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5fda40a1-b8cd-45d1-9899-eba8d558e33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "malmungchi_attention_masks = []\n",
    "\n",
    "for num in malmungchi_input_id:\n",
    "    attention_sample_mask = [float(i>0) for i in num]\n",
    "    malmungchi_attention_masks.append(attention_sample_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "46f9a7de-9a2c-408a-af28-172d738c4c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "malmungchi_x_train, malmungchi_x_test, malmungchi_y_train, malmungchi_y_test = train_test_split(malmungchi_input_id, malmungchi_label_list, random_state=2, test_size=0.2, shuffle=True)\n",
    "malmungchi_mask_train, sample_mask_test, temp_train_id, temp_test_id= train_test_split(malmungchi_attention_masks, malmungchi_input_id, random_state=2, test_size=0.2, shuffle=True)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f28417ac-858e-4d1d-bd09-73c2ad71c936",
   "metadata": {},
   "outputs": [],
   "source": [
    "malmungchi_x_val, malmungchi_x_eval, malmungchi_y_val, malmungchi_y_eval = train_test_split(malmungchi_x_test, malmungchi_y_test, test_size=0.1, random_state=2, shuffle=True)\n",
    "malmungchi_mask_val, malmungchi_mask_eval, _, _ = train_test_split(sample_mask_test, temp_test_id, random_state=2, test_size=0.1, shuffle=True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a5f711cd-6ef6-41e3-89c1-29e12610c281",
   "metadata": {},
   "outputs": [],
   "source": [
    "malmungchi_train_inputs = torch.tensor(malmungchi_x_train)\n",
    "malmungchi_train_labels = torch.tensor(malmungchi_y_train)\n",
    "malmungchi_train_masks = torch.tensor(malmungchi_mask_train)\n",
    "\n",
    "malmungchi_val_inputs = torch.tensor(malmungchi_x_val)\n",
    "malmungchi_val_labels = torch.tensor(malmungchi_y_val)\n",
    "malmungchi_val_masks = torch.tensor(malmungchi_mask_val)  \n",
    "\n",
    "malmungchi_eval_inputs2 = torch.tensor(malmungchi_x_eval)\n",
    "malmungchi_eval_labels2 = torch.tensor(malmungchi_y_eval)\n",
    "malmungchi_eval_masks2 = torch.tensor(malmungchi_mask_eval)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4ec98410-e734-4cb4-b528-2251b352f525",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "malmungchi_train_data = TensorDataset(malmungchi_train_inputs, malmungchi_train_masks, malmungchi_train_labels)\n",
    "malmungchi_train_sampler = RandomSampler(malmungchi_train_data)\n",
    "malmungchi_train_dataloader = DataLoader(malmungchi_train_data, sampler=malmungchi_train_sampler, batch_size=BATCH_SIZE)\n",
    "\n",
    "malmungchi_val_data = TensorDataset(malmungchi_val_inputs, malmungchi_val_masks, malmungchi_val_labels)\n",
    "malmungchi_val_sampler = SequentialSampler(malmungchi_val_data)\n",
    "malmungchi_val_dataloader = DataLoader(malmungchi_val_data, sampler=malmungchi_val_sampler, batch_size=BATCH_SIZE)\n",
    "\n",
    "malmungchi_eval_data2 = TensorDataset(malmungchi_eval_inputs2, malmungchi_eval_masks2, malmungchi_eval_labels2)\n",
    "malmungchi_eval_sampler2 = SequentialSampler(malmungchi_eval_data2)\n",
    "malmungchi_eval_dataloader2 = DataLoader(malmungchi_eval_data2, sampler=malmungchi_eval_sampler2, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e2d869-6117-4823-af4b-ca84b11bd787",
   "metadata": {},
   "source": [
    "## 5.2 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ba72fbd5-a181-42a1-b995-9538d2b19422",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(SemanticScorePrediction.parameters(),\n",
    "                  lr = 2e-5, # 학습률(learning rate)\n",
    "                  eps = 1e-8 \n",
    "                )\n",
    "\n",
    "# 에폭수\n",
    "epochs = 30\n",
    "\n",
    "# 총 훈련 스텝 : 배치반복 횟수 * 에폭\n",
    "total_steps = len(malmungchi_train_dataloader) * epochs\n",
    "\n",
    "# 스케줄러 생성\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5d8d828e-6523-4dd1-8ba0-3d484ea6e132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.55\n",
      "  Training epcoh took: 0:01:10\n",
      "\n",
      "======== Epoch 2 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.48\n",
      "  Training epcoh took: 0:01:11\n",
      "\n",
      "======== Epoch 3 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.46\n",
      "  Training epcoh took: 0:01:11\n",
      "\n",
      "======== Epoch 4 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.45\n",
      "  Training epcoh took: 0:01:10\n",
      "\n",
      "======== Epoch 5 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.39\n",
      "  Training epcoh took: 0:01:11\n",
      "\n",
      "======== Epoch 6 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.33\n",
      "  Training epcoh took: 0:01:10\n",
      "\n",
      "======== Epoch 7 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.26\n",
      "  Training epcoh took: 0:01:11\n",
      "\n",
      "======== Epoch 8 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.21\n",
      "  Training epcoh took: 0:01:10\n",
      "\n",
      "======== Epoch 9 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.18\n",
      "  Training epcoh took: 0:01:10\n",
      "\n",
      "======== Epoch 10 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.12\n",
      "  Training epcoh took: 0:01:10\n",
      "\n",
      "======== Epoch 11 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.10\n",
      "  Training epcoh took: 0:01:10\n",
      "\n",
      "======== Epoch 12 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.05\n",
      "  Training epcoh took: 0:01:11\n",
      "\n",
      "======== Epoch 13 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.04\n",
      "  Training epcoh took: 0:01:10\n",
      "\n",
      "======== Epoch 14 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.04\n",
      "  Training epcoh took: 0:01:09\n",
      "\n",
      "======== Epoch 15 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.04\n",
      "  Training epcoh took: 0:01:11\n",
      "\n",
      "======== Epoch 16 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.03\n",
      "  Training epcoh took: 0:01:11\n",
      "\n",
      "======== Epoch 17 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epcoh took: 0:01:10\n",
      "\n",
      "======== Epoch 18 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epcoh took: 0:01:10\n",
      "\n",
      "======== Epoch 19 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epcoh took: 0:01:10\n",
      "\n",
      "======== Epoch 20 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epcoh took: 0:01:10\n",
      "\n",
      "======== Epoch 21 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:01:10\n",
      "\n",
      "======== Epoch 22 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:01:10\n",
      "\n",
      "======== Epoch 23 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:01:11\n",
      "\n",
      "======== Epoch 24 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epcoh took: 0:01:11\n",
      "\n",
      "======== Epoch 25 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:01:10\n",
      "\n",
      "======== Epoch 26 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epcoh took: 0:01:10\n",
      "\n",
      "======== Epoch 27 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epcoh took: 0:01:11\n",
      "\n",
      "======== Epoch 28 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epcoh took: 0:01:10\n",
      "\n",
      "======== Epoch 29 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epcoh took: 0:01:11\n",
      "\n",
      "======== Epoch 30 / 30 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epcoh took: 0:01:10\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "#랜덤시드 고정\n",
    "seed_val = 14\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "#그래디언트 초기화\n",
    "SemanticScorePrediction.zero_grad()\n",
    "\n",
    "# 학습\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # 시작 시간 설정\n",
    "    t0 = time.time()\n",
    "\n",
    "    # 로스 초기화\n",
    "    total_loss = 0\n",
    "\n",
    "    # 훈련모드로 변경\n",
    "    SemanticScorePrediction.train()\n",
    "        \n",
    "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
    "    for step, batch in enumerate(malmungchi_train_dataloader):\n",
    "        # 경과 정보 표시\n",
    "        if step % 500 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(malmungchi_train_dataloader), elapsed))\n",
    "\n",
    "        # 배치를 GPU에 넣음\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        # 배치에서 데이터 추출\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        for i in range(len(b_labels)):\n",
    "            b_labels[i] += 1\n",
    "\n",
    "        # Forward 수행                \n",
    "        outputs = SemanticScorePrediction(b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask,\n",
    "                        turn_ids = None,\n",
    "                        labels=b_labels)\n",
    "        \n",
    "        # 로스 구함\n",
    "        loss = outputs[0]\n",
    "\n",
    "        # 총 로스 계산\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backward 수행으로 그래디언트 계산\n",
    "        loss.backward()\n",
    "\n",
    "        # 그래디언트 클리핑\n",
    "        torch.nn.utils.clip_grad_norm_(SemanticScorePrediction.parameters(), 1.0)\n",
    "\n",
    "        # 그래디언트를 통해 가중치 파라미터 업데이트\n",
    "        optimizer.step()\n",
    "\n",
    "        # 스케줄러로 학습률 감소\n",
    "        scheduler.step()\n",
    "\n",
    "        # 그래디언트 초기화\n",
    "        SemanticScorePrediction.zero_grad()\n",
    "\n",
    "    # 평균 로스 계산\n",
    "    avg_train_loss = total_loss / len(malmungchi_train_dataloader)            \n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a279a5d4-84ff-4137-b07e-ba2b26a816d3",
   "metadata": {},
   "source": [
    "## 5.3 Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f76006ec-a2a2-4aad-9f7b-ed35ec7a0c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Accuracy]: 82.79%\n",
      "  [Precision]: 40.30%\n",
      "  [Recall]: 45.94%\n",
      "  [F1_Score]: 41.81%\n",
      "  [RMSE]: 0.45\n",
      "  Validation took: 0:01:15\n"
     ]
    }
   ],
   "source": [
    "#Validation\n",
    "\n",
    "logits_results = np.array([])\n",
    "label_ids_results = np.array([])\n",
    "eval_loss, eval_accuracy = 0, 0\n",
    "nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "# 데이터로더에서 배치만큼 반복하여 가져옴\n",
    "for batch in malmungchi_val_dataloader:\n",
    "    # 배치를 GPU에 넣음\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "    # 배치에서 데이터 추출\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    \n",
    "    for i in range(len(b_labels)):\n",
    "        b_labels[i] += 1\n",
    "\n",
    "    # 그래디언트 계산 안함\n",
    "    with torch.no_grad():     \n",
    "        # Forward 수행\n",
    "        outputs = SemanticScorePrediction(b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask,\n",
    "                        turn_ids = None,\n",
    "                        labels=b_labels)\n",
    "\n",
    "    #로짓 구함\n",
    "    logits = outputs[1]\n",
    "    #print(logits)\n",
    "    # CPU로 데이터 이동\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    logits = np.argmax(logits, axis=1)\n",
    "\n",
    "    logits_results = np.append(logits_results, logits)\n",
    "    label_ids_results = np.append(label_ids_results, label_ids)\n",
    "    \n",
    "\n",
    "# 출력 로스과 라벨을 비교하여 정확도 계산\n",
    "tmp_eval_accuracy = flat_accuracy(logits_results, label_ids_results)\n",
    "eval_accuracy += tmp_eval_accuracy\n",
    "nb_eval_steps += 1\n",
    "acc, prec, recall, f1, RMSE = evaluation_metrics(logits_results, label_ids_results)\n",
    "\n",
    "print('  [Accuracy]: {:.2f}%'.format(acc * 100))\n",
    "print('  [Precision]: {:.2f}%'.format(prec * 100))\n",
    "print('  [Recall]: {:.2f}%'.format(recall * 100))\n",
    "print('  [F1_Score]: {:.2f}%'.format(f1 * 100))\n",
    "print('  [RMSE]: {:.2f}'.format(RMSE))\n",
    "print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2902285-166a-445f-8073-b48cf22c657f",
   "metadata": {},
   "source": [
    "## 5.4 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c3be09d5-f58c-45a7-843d-06dd0860c8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Accuracy]: 79.38%\n",
      "  [Precision]: 57.56%\n",
      "  [Recall]: 59.61%\n",
      "  [F1_Score]: 58.26%\n",
      "  [RMSE]: 0.45\n",
      "  Evaluation took: 0:00:01\n"
     ]
    }
   ],
   "source": [
    "#Evaluation\n",
    "#시작 시간 설정\n",
    "t0 = time.time()\n",
    "\n",
    "# 평가모드로 변경\n",
    "SemanticScorePrediction.eval()\n",
    "score_list_final=[]\n",
    "\n",
    "# 변수 초기화\n",
    "eval_loss, eval_accuracy = 0, 0\n",
    "nb_eval_steps, nb_eval_examples = 0, 0\n",
    "logits_results = np.array([])\n",
    "label_ids_results = np.array([])\n",
    "\n",
    "# 데이터로더에서 배치만큼 반복하여 가져옴\n",
    "for step, batch in enumerate(malmungchi_eval_dataloader2):\n",
    "    # 경과 정보 표시\n",
    "    if step % 100 == 0 and not step == 0:\n",
    "        elapsed = format_time(time.time() - t0)\n",
    "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(malmungchi_eval_dataloader2), elapsed))\n",
    "\n",
    "    # 배치를 GPU에 넣음\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    \n",
    "    # 배치에서 데이터 추출\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(len(b_labels)):\n",
    "            b_labels[i] += 1\n",
    "        \n",
    "    # 그래디언트 계산 안함\n",
    "    with torch.no_grad():     \n",
    "        # Forward 수행\n",
    "        outputs = SemanticScorePrediction(b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        turn_ids=None,\n",
    "                        attention_mask=b_input_mask)\n",
    "    \n",
    "    # 로스 구함\n",
    "    logits = outputs[0]\n",
    "    \n",
    "    #score_list=relation_score_prediction(logits)\n",
    "    #score_list_final.append(score_list)\n",
    "    \n",
    "    # CPU로 데이터 이동\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    \n",
    "    \n",
    "    logits = np.argmax(logits, axis=1)\n",
    "\n",
    "    logits_results = np.append(logits_results, logits)\n",
    "    label_ids_results = np.append(label_ids_results, label_ids)\n",
    "                                  \n",
    "    #print(\"============================================================================================================Dialogue============================================================================================================\")\n",
    "    #print(malmungchi_data_list[:5])\n",
    "    \n",
    "    #print(\"=======================================================================================================Dialogue Integer Encoding=======================================================================================================\")\n",
    "    #print(b_input_ids[:5])\n",
    "                                  \n",
    "    #print(\"============================================================================================================argmax[logits]============================================================================================================\")\n",
    "    #print(logits[:5])\n",
    "    \n",
    "    #print(\"============================================================================================================Relation Score============================================================================================================\")\n",
    "    #print(score_list[:5])\n",
    "\n",
    "# 출력 로스과 라벨을 비교하여 정확도 계산\n",
    "tmp_eval_accuracy = flat_accuracy(logits_results, label_ids_results)\n",
    "eval_accuracy += tmp_eval_accuracy\n",
    "nb_eval_steps += 1\n",
    "acc, prec, recall, f1, RMSE = evaluation_metrics(logits_results, label_ids_results)\n",
    "\n",
    "print('  [Accuracy]: {:.2f}%'.format(acc * 100))\n",
    "print('  [Precision]: {:.2f}%'.format(prec * 100))\n",
    "print('  [Recall]: {:.2f}%'.format(recall * 100))\n",
    "print('  [F1_Score]: {:.2f}%'.format(f1 * 100))\n",
    "print('  [RMSE]: {:.2f}'.format(RMSE))\n",
    "print(\"  Evaluation took: {:}\".format(format_time(time.time() - t0)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-showcode": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
